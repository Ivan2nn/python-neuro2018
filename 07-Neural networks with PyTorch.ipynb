{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building neural networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # import the PyTorch package\n",
    "import torchvision # import trochvision package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tensors - enhanced NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.Tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why PyTorch Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensors can be run on **GPUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load a **training set** that we are going to use to train our network and a separate **test set** that we'll use to evaluate the performance of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use convenience methods in `torchvision.datasets` to download various popular machine learning benchmark images. Here we are going to download [**MNIST**](http://yann.lecun.com/exdb/mnist/) which is a collection of handwritten digits along with labels (i.e. what digit was drawn).\n",
    "\n",
    "The MNIST dataset consists of a total of 70,000 images, of which 60,000 are desginated as the **training set** and 10,000 are designated as the **test set**. This standardized separation allows everyone around the world to evaluate and compare their model's performances with each other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST('./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns Torchvision's special **dataset** object that can be used to represent **supervised datasets** consisting of both inputs (i.e. images) and targets (i.e. digit labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_set[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Digit: 5')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)\n",
    "plt.title('Digit: {}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the test set in an identical fashion, passing in `train=False` into `MNIST`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.MNIST('./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_set[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Digit: 1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)\n",
    "plt.title('Digit: {}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even before you start feeding in your images into a neural network, it is very common to perform some data transformations - modifying images in some fixed manner that makes it easier to work with them.\n",
    "\n",
    "One of the most common image transformation is **normalization**, where you first compute mean and standard deviation across all images (typically in the training set). You then subtract the mean from each image and also divide each image by the standard deviation. If you did this, and recomputed the mean and standard deviation across all images, you will find that they now have **mean of 0** and **standard deviation of 1**, and thus they are said to be **normalized**.\n",
    "\n",
    "Normalization helps ensure input image intensities stay within some expected range, allowing the network to not have to worry about large variations in image values that is otherwise visually uninteresting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, when you load images from Torchvision, they are provided as Pillow package's Image object. Pillow is one of Python's popular image processing package, and there images are represented by a dedicated Image object with a lot of methods implementing common image processing operations.\n",
    "\n",
    "However, in PyTorch, networks only understands PyTorch Tensors, and thus we must convert the images from Pillow Image into PyTorch Tensor before we can pass the image into the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can achieve these two *transformations* by making use of Torchvision's transformation operations. You combine multiple transformation operations together and pass it at the time of dataset loading. This returns a dataset that **applies these transformations** automatically on all images! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a transformation that will:\n",
    "1. convert images into PyTorch tensors\n",
    "2. normalize the images against the mean of 0.1307 and standard deviation of 0.3081."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms # get torchvision's transforms subpackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a composite transform that first converts images to tensors and then normalize the images\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # converts images into Tensors\n",
    "    transforms.Normalize([0.1307], [0.3081])\n",
    "])\n",
    "\n",
    "# apply the transforms at the time of dataset loading\n",
    "training_set = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                                          transform=image_transform)\n",
    "test_set = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                                          transform=image_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now any image you access through the dataset has the transformation already applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, you define a new neural network by defining a **new class that inherits from nn.Module** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this better, let's take a quick review of classes and learn the new concept of **object inheritance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the past session, we have taken a look at defining a **class** to represent a grouping of data and functions, where each **instance of a class** or **object** can be thought of as representing a concrete unit that has **properties** and **behavior** (or **methods**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, name):\n",
    "        self.name = name  # assign name\n",
    "        \n",
    "    def title(self):\n",
    "        return \"an ordinary person.\"\n",
    "    \n",
    "    def greeting(self):\n",
    "        print('Hello! My name is {}.'.format(self.name))\n",
    "        print(\"I'm {}\".format(self.title()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar = Person('Edgar')\n",
    "john = Person('John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is Edgar.\n",
      "I'm an ordinary person.\n"
     ]
    }
   ],
   "source": [
    "edgar.greeting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is John.\n",
      "I'm an ordinary person.\n"
     ]
    }
   ],
   "source": [
    "john.greeting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that both `edgar` and `john` are objects of type (class) `Person`. They both have properties called `name` that is unique to each, and have the common behaviors (method) called `greeting` that prints out a greeting message introducing themselves. Note that `greeting` method calls another method `title` in creating the intro statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key of Object-Oriented Programming (OOP) is to group certain data (e.g. `name`) with behavior (e.g. `greeting`, `title`) that when put together can be used to represent a conceptual grouping that may correspond to some real world *objects*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialization via inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine that you want to define a new **class** of object called `Scientist` that has everything that a `Person`  has (e.g.`name`, `greeting`, and `title`), but has extra property called `topic` that specified their research topic, and has a new behavior (i.e. *method*) called `research` that finds a significant result at p-value < 0.05. \n",
    "\n",
    "Without worry much about code duplication, you could implement it as such: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Scientist:\n",
    "    def __init__(self, name, topic):\n",
    "        self.name = name\n",
    "        self.topic = topic\n",
    "        \n",
    "    def title(self):\n",
    "        return \"an ordinary person.\"\n",
    "    \n",
    "    def greeting(self):\n",
    "        print('Hello! My name is {}.'.format(self.name))\n",
    "        print(\"I'm {}\".format(self.title()))\n",
    " \n",
    "    def research(self, silent=False):\n",
    "        print('Performing a research on the topic {}...'.format(self.topic))\n",
    "        pvalue = random.random() # randomly pick a value between [0, 1)\n",
    "        \n",
    "        if pvalue < 0.05:\n",
    "            if not silent:\n",
    "                print('Results statistically significant with p-value={:0.3f}!! Publish!!'.format(pvalue))\n",
    "            return True\n",
    "        else:\n",
    "            if not silent:\n",
    "                print('Results was not significant with p-value={:0.3f}... Continue working...'.format(pvalue))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar = Scientist(name='Edgar', topic='computational neuroscience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is Edgar.\n",
      "I'm an ordinary person.\n"
     ]
    }
   ],
   "source": [
    "edgar.greeting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing a research on the topic computational neuroscience...\n",
      "Results was not significant with p-value=0.793... Continue working...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgar.research()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now notice that there is a lot of repeated code between a `Person` and a `Scientist`. Both has property called `name` and a method called `greeting`. After all, a Scientist **is a** Person, right? When one class can be thought of as a **specialization** of another class, you can save alot of typing and code duplication by using **class inheritance**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Scientist(Person):  # Scientist inherits from Person\n",
    "    def __init__(self, name, topic):\n",
    "        super().__init__(name)\n",
    "        self.topic = topic\n",
    "\n",
    "    def research(self, silent=False):\n",
    "        print('Performing a research on the topic {}...'.format(self.topic))\n",
    "        pvalue = random.random() # randomly pick a value between [0, 1)\n",
    "        \n",
    "        if pvalue < 0.05:\n",
    "            if not silent:\n",
    "                print('Results statistically significant with p-value={:0.3f}!! Publish!!'.format(pvalue))\n",
    "            return True\n",
    "        else:\n",
    "            if not silent:\n",
    "                print('Results was not significant with p-value={:0.3f}... Continue working...'.format(pvalue))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "moku = Scientist(name='Moku', topic='physics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is Edgar.\n",
      "I'm an ordinary person.\n"
     ]
    }
   ],
   "source": [
    "edgar.greeting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing a research on the topic computational neuroscience...\n",
      "Results statistically significant with p-value=0.048!! Publish!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgar.research()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `Scientist` class no longer implements the `greeting` and `eat` methods, yet you can still call them on the instance of `Scientist`. This is because these methods were **inherited** from `Person` class.\n",
    "\n",
    "Furthermore, we call something funny inside the `__init__` method: `super().__init__(name)`. As you may be able to guess, this calls the initializer of `Person` or the **super class**, passing in the value it expects (e.g. `name` of the person). This allows any complex configuration that `Person` might have done in its `__init__` to be reused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can **override** super class's implementation of a method to give a new, specialized behavior to an existing method! Here, let's **override** the implementation of the method `title`, in effect cusotmizing the introduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Scientist(Person):  # Scientist inherits from Person\n",
    "    def __init__(self, name, topic):\n",
    "        super().__init__(name)\n",
    "        self.topic = topic\n",
    "        \n",
    "    # overriding title method\n",
    "    def title(self):\n",
    "        return \"a scentist in {}\".format(self.topic)\n",
    "\n",
    "    def research(self, silent=False):\n",
    "        print('Performing a research on the topic {}...'.format(self.topic))\n",
    "        pvalue = random.random() # randomly pick a value between [0, 1)\n",
    "        \n",
    "        if pvalue < 0.05:\n",
    "            if not silent:\n",
    "                print('Results statistically significant with p-value={:0.3f}!! Publish!!'.format(pvalue))\n",
    "            return True\n",
    "        else:\n",
    "            if not silent:\n",
    "                print('Results was not significant with p-value={:0.3f}... Continue working...'.format(pvalue))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgar = Scientist(name='Edgar', topic='computational neuroscience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is Edgar.\n",
      "I'm a scentist in computational neuroscience\n"
     ]
    }
   ],
   "source": [
    "edgar.greeting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we were able to modify the behaivor of an already existing method `greeting` by overriding the behavior of the another method `title`. This pattern in which you can **customize** behavior of an already existing mechanism by overriding another method happens quite commonly. In fact, we will soon encounter them in implementing our neural network in PyTorch!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks inherit from *nn.Module*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now armed with knowlege of class inheritance, let's take another look at a typical definition of a neural network in PyTorch. In PyTorch, any network **is a** `nn.Module`. In other words, you define a new class that inherits from `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(5, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.fc(x)\n",
    "        z = F.relu(y)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that `MyNetwork` *inherits from* `nn.Module`. This gives our class `MyNetwork` with a lot of properties and methods that is already part of `nn.Module`, and this is precisely what allows you to define a new neural network with minimal work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A network in PyTorch (which is a class), typically consists of one or more **layers** that you create and hold on to inside the `__init__` method. Here, we are defining a single `nn.Linear` layer which corresponds to a *fully-connected* linear layer connecting from 5 input nodes into 10 output nodes. We **instantiate** this layer and assign it to the object's property named `fc` (standing for **f**ully **c**onnected layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the `__init__`, we have not computed anything. We simply instantiated a layer and assigned it to a property for *later use*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real use of a PyTorch module comes in when you **instantiate** the class - that is, you create an object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This action just created a new **instance** of the network, with it's own network weights that can be trained!\n",
    "\n",
    "A key feature of a module is the fact that you can use it like a function - it accepts an input and returns an output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0695,  0.4837,  0.0000,  0.0000,  0.2656,  0.0000,  0.0172,\n",
       "          0.0000,  0.3369,  0.0000]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 5) # a simple vector of 5 elements - or 5 input values\n",
    "\n",
    "y = net(x) # you use a module instance like a function!\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The secret behind this is the `forward` method we defined in the `MyNetwork` class:\n",
    "\n",
    "```python\n",
    " def forward(self, x):\n",
    "    y = self.fc(x)\n",
    "    z = F.relu(y)\n",
    "    return z\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, we accepted a parameter `x`, and we used the fully-connected linear layer `self.fc` as a function with `x` as the input!\n",
    "\n",
    "It turns out that `nn.Linear` is yet another **subclass** of `nn.Module` and thus can take input, return output. Our particular `self.fc` was configured to take in input of size 5 and output vector of size 10.\n",
    "\n",
    "The `F.relu` is then an element-wise operation that clips any value less than 0 to 0, while keeping positive values as is. `forward` function finally returns the output of `relu` and that becomes the output of the whole network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, `MyNetwork` implemented a **single full-connected layer neural network with ReLU output non-linearity** - one of the simplest networks you can construct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building network to classify images into digits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have seen how to build a network by defining a new class that inherits from `nn.Module`, let's try to implement a network that takes in a $28 \\times 28$ pixels gray scale image of a digit and classifies them into 1 of 10 digits!\n",
    "\n",
    "The input will be one or more images of size $28 \\times 28$, and we are going to set **the output to be a vector of size 10** where each position indicates a *log probability* that the image belongs to the specific digit.\n",
    "\n",
    "We'll start with a simplest possible implementation where we **flatten out** the input image into a vector of size 28 * 28 = 784. This will be **fully connected neural network with no output nonlinearity** linking 784 input nodes into 10 output nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flattens an image of form N x 1 x 28 x 28 -> N x 784\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1) # make sure that probabilities add up to one, and then take log\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the network and run an image through it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = test_set[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x118ac4cf8>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9762, -2.1093, -2.4735, -2.6918, -3.4270, -3.2984, -1.9790,\n",
       "         -2.4868, -1.4873, -2.6417]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a log of class probabilities, so we can exponentiate this to get the actual probability over classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1386,  0.1213,  0.0843,  0.0678,  0.0325,  0.0369,  0.1382,\n",
       "          0.0832,  0.2260,  0.0712]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(net(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perhaps take the index with the largest probability as the network's best guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.exp(net(image))\n",
    "torch.argmax(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the label is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can see that our network is not quite performing well. That's expected because our network is **randomly initialized**! In order to get a reasonable performance, we need to **train** the network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to **train our network** by minimizing a **loss function** - a function that evaluates how *off* we are from the true target of the world. Chosing a good loss function can influence how well your network performs. In the case of **N-way classification** problem where the output is a vector of size *N*, it's quite common to treat the output as the log probability of N classes, and optimize the network by miniminzg **negative log likelihood**. This is akin to adjusting the network weights so that the correct class would have the higest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a network we will also "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Scientist(Person):  # Scientist inherits from Person\n",
    "    def __init__(self, name, topic):\n",
    "        super().__init__(name)\n",
    "        self.topic = topic\n",
    "\n",
    "    def research(self, silent=False):\n",
    "        print('Performing a research on the topic {}...'.format(self.topic))\n",
    "        pvalue = random.random() # randomly pick a value between [0, 1)\n",
    "        \n",
    "        if pvalue < 0.05:\n",
    "            if not silent:\n",
    "                print('Results statistically significant with p-value={:0.3f}!! Publish!!'.format(pvalue))\n",
    "            return True\n",
    "        else:\n",
    "            if not silent:\n",
    "                print('Results was not significant with p-value={:0.3f}... Continue working...'.format(pvalue))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12bd1a320>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    args = parser.parse_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
